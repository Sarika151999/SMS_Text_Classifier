{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SMS_Text_Classifier.py",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPFqM35nJGU77uQC41WgbZC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sarika151999/SMS_Text_Classifier/blob/main/SMS_Text_Classifier_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9709o0rv6nKa"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq-y3CNJ6-Nm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMHwYXHXCar3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d947bf3-3068-41ad-9152-ff1afd0ec590"
      },
      "source": [
        "# get data files\n",
        "TRAIN_DATA_URL = \"https://raw.githubusercontent.com/beaucarnes/fcc_python_curriculum/master/sms/train-data.tsv\"\n",
        "TEST_DATA_URL = \"https://raw.githubusercontent.com/beaucarnes/fcc_python_curriculum/master/sms/valid-data.tsv\"\n",
        "\n",
        "train_file_path = tf.keras.utils.get_file(\"train-data.tsv\", TRAIN_DATA_URL)\n",
        "test_file_path = tf.keras.utils.get_file(\"valid-data.tsv\", TEST_DATA_URL)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/beaucarnes/fcc_python_curriculum/master/sms/train-data.tsv\n",
            "360448/358233 [==============================] - 0s 0us/step\n",
            "Downloading data from https://raw.githubusercontent.com/beaucarnes/fcc_python_curriculum/master/sms/valid-data.tsv\n",
            "122880/118774 [===============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa9Z6oy06-Uj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_h508FEClxO"
      },
      "source": [
        "# convert data to pandas dataframe and change labels to numbers\n",
        "df_train = pd.read_csv(train_file_path,sep='\\t',header=None)\n",
        "df_test = pd.read_csv(test_file_path,sep='\\t',header=None)\n",
        "df_train[0] = df_train[0].replace(\"ham\", 0)\n",
        "df_train[0] = df_train[0].replace(\"spam\", 1)\n",
        "df_test[0] = df_test[0].replace(\"ham\", 0)\n",
        "df_test[0] = df_test[0].replace(\"spam\", 1)\n",
        "df_test[0]=df_test[0].astype('int64')\n",
        "df_train[0]=df_train[0].astype('int64')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw76fFC6CpG7"
      },
      "source": [
        "# convert data to TensorFlow datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((df_train[1], df_train[0]))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((df_test[1], df_test[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N11lwuMfCtnE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e90cc670-3a4f-4e0d-8a67-269c505b9d38"
      },
      "source": [
        "# build vocab list\n",
        "\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "tokenizer = tfds.deprecated.text.Tokenizer()\n",
        "\n",
        "vocabulary_set = set()\n",
        "for text_tensor, _ in train_dataset.concatenate(test_dataset):\n",
        "  some_tokens = tokenizer.tokenize(text_tensor.numpy())\n",
        "  vocabulary_set.update(some_tokens)\n",
        "\n",
        "vocab_size = len(vocabulary_set)\n",
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8741"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYVf9NdQCwJE"
      },
      "source": [
        "# create encoder based on vocab list\n",
        "encoder = tfds.deprecated.text.TokenTextEncoder(vocabulary_set)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJM14PZPCz-c"
      },
      "source": [
        "# encode datasets\n",
        "def encode(text_tensor, label):\n",
        "  encoded_text = encoder.encode(text_tensor.numpy())\n",
        "  return encoded_text, label\n",
        "\n",
        "def encode_map_fn(text, label):\n",
        "  encoded_text, label = tf.py_function(encode, \n",
        "                                       inp=[text, label], \n",
        "                                       Tout=(tf.int64, tf.int64))\n",
        "  encoded_text.set_shape([None])\n",
        "  label.set_shape([])\n",
        "\n",
        "  return encoded_text, label\n",
        "\n",
        "\n",
        "train_dataset_encoded = train_dataset.map(encode_map_fn)\n",
        "test_dataset_encoded = test_dataset.map(encode_map_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXmkFNAW8nB1",
        "outputId": "b406bdea-8ae5-42b4-a7be-18ced4b47c93"
      },
      "source": [
        "# check what data looks like after encoding\n",
        "for train_example, train_label in train_dataset_encoded.take(2):\n",
        "  print('Encoded text:', train_example[:10].numpy())\n",
        "  print('Label:', train_label.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoded text: [ 915 3970  528 6585 5111 7014 7811 6165 5594  618]\n",
            "Label: 0\n",
            "Encoded text: [7742 7847 7220 7072 4567]\n",
            "Label: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3nxXYQO8sVk"
      },
      "source": [
        "# prepare data for training, padded_batch is used to make all reviews the same length while batching\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "train_batches = (\n",
        "    train_dataset_encoded\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .padded_batch(32))\n",
        "\n",
        "test_batches = (\n",
        "    test_dataset_encoded\n",
        "    .padded_batch(32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4j-13kC8v68",
        "outputId": "f3b66611-ac1f-45a8-de9e-26016f54433c"
      },
      "source": [
        "# build neural network model\n",
        "model = keras.Sequential([\n",
        "  keras.layers.Embedding(encoder.vocab_size, 16),\n",
        "  keras.layers.GlobalAveragePooling1D(),\n",
        "  keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          139888    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 139,905\n",
            "Trainable params: 139,905\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzXQetRd81aT",
        "outputId": "cf3a5da7-48f5-4d94-80d9-0ea99e362839"
      },
      "source": [
        "# train model\n",
        "history = model.fit(train_batches,\n",
        "                    epochs=10,\n",
        "                    validation_data=test_batches,\n",
        "                    validation_steps=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "131/131 [==============================] - 3s 16ms/step - loss: 0.5796 - accuracy: 0.8519 - val_loss: 0.4565 - val_accuracy: 0.8604\n",
            "Epoch 2/10\n",
            "131/131 [==============================] - 2s 15ms/step - loss: 0.3712 - accuracy: 0.8662 - val_loss: 0.3156 - val_accuracy: 0.8635\n",
            "Epoch 3/10\n",
            "131/131 [==============================] - 2s 15ms/step - loss: 0.2831 - accuracy: 0.8758 - val_loss: 0.2699 - val_accuracy: 0.8740\n",
            "Epoch 4/10\n",
            "131/131 [==============================] - 2s 15ms/step - loss: 0.2473 - accuracy: 0.8954 - val_loss: 0.2420 - val_accuracy: 0.8906\n",
            "Epoch 5/10\n",
            "131/131 [==============================] - 2s 15ms/step - loss: 0.2205 - accuracy: 0.9084 - val_loss: 0.2161 - val_accuracy: 0.9052\n",
            "Epoch 6/10\n",
            "131/131 [==============================] - 2s 15ms/step - loss: 0.1945 - accuracy: 0.9244 - val_loss: 0.1924 - val_accuracy: 0.9187\n",
            "Epoch 7/10\n",
            "131/131 [==============================] - 2s 15ms/step - loss: 0.1716 - accuracy: 0.9352 - val_loss: 0.1709 - val_accuracy: 0.9281\n",
            "Epoch 8/10\n",
            "131/131 [==============================] - 2s 15ms/step - loss: 0.1508 - accuracy: 0.9423 - val_loss: 0.1521 - val_accuracy: 0.9427\n",
            "Epoch 9/10\n",
            "131/131 [==============================] - 2s 15ms/step - loss: 0.1405 - accuracy: 0.9466 - val_loss: 0.1362 - val_accuracy: 0.9500\n",
            "Epoch 10/10\n",
            "131/131 [==============================] - 2s 15ms/step - loss: 0.1220 - accuracy: 0.9567 - val_loss: 0.1223 - val_accuracy: 0.9563\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4a6fq9Z9B3k",
        "outputId": "156f3d9d-4753-4e99-ab9d-cccfed151a4a"
      },
      "source": [
        "# evaluate model\n",
        "loss, accuracy = model.evaluate(test_batches)\n",
        "\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44/44 [==============================] - 1s 13ms/step - loss: 0.1259 - accuracy: 0.9533\n",
            "Loss:  0.12590965628623962\n",
            "Accuracy:  0.9533045887947083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8vOpKup9GcN",
        "outputId": "222c85ca-1861-4cb7-e409-afedcdb5f279"
      },
      "source": [
        "# function to predict messages based on model\n",
        "# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
        "def predict_message(pred_text):\n",
        "  encoded_pred_text = encoder.encode(pred_text)\n",
        "  encoded_pred_text = tf.cast(encoded_pred_text, tf.float32)\n",
        "  prediction = model.predict(tf.expand_dims(encoded_pred_text, tf.constant(0))).tolist()\n",
        "  prediction = prediction[0]\n",
        "  if prediction[0] < .5:\n",
        "    prediction.append(\"ham\")\n",
        "  else:\n",
        "    prediction.append(\"spam\")\n",
        "\n",
        "  return (prediction)\n",
        "\n",
        "pred_text = \"how are you doing today?\"\n",
        "\n",
        "prediction = predict_message(pred_text)\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.00956571102142334, 'ham']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fH2o_ip39Lg_",
        "outputId": "ca17f6f1-dae9-49ae-999c-1f92d30c47c7"
      },
      "source": [
        "# Run this cell to test your function and model. Do not modify contents.\n",
        "def test_predictions():\n",
        "  test_messages = [\"how are you doing today\",\n",
        "                   \"sale today! to stop texts call 98912460324\",\n",
        "                   \"i dont want to go. can we try it a different day? available sat\",\n",
        "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
        "                   \"you have won Â£1000 cash! call to claim your prize.\",\n",
        "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
        "                   \"wow, is your arm alright. that happened to me one time too\"\n",
        "                  ]\n",
        "\n",
        "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
        "  passed = True\n",
        "\n",
        "  for msg, ans in zip(test_messages, test_answers):\n",
        "    prediction = predict_message(msg)\n",
        "    if prediction[1] != ans:\n",
        "      passed = False\n",
        "\n",
        "  if passed:\n",
        "    print(\"You passed the challenge. Great job!\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying.\")\n",
        "\n",
        "test_predictions()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You passed the challenge. Great job!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}